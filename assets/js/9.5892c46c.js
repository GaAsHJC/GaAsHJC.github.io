(window.webpackJsonp=window.webpackJsonp||[]).push([[9],{328:function(e,n,r){},362:function(e,n,r){"use strict";r(328)},378:function(e,n,r){"use strict";r.r(n);r(362);var t=r(45),a=Object(t.a)({},(function(){var e=this,n=e.$createElement,r=e._self._c||n;return r("ContentSlotsDistributor",{attrs:{"slot-key":e.$parent.slotKey}},[r("ProfileSection",{attrs:{frontmatter:e.$page.frontmatter}}),e._v(" "),r("h2",{attrs:{id:"about-me"}},[e._v("About Me")]),e._v(" "),r("p",[e._v("I'm currently a PhD student in the "),r("a",{attrs:{href:"https://vcg.xmu.edu.cn/",target:"_blank",rel:"noopener noreferrer"}},[e._v("Visual Computing and Graphics Lab"),r("OutboundLink")],1),e._v(" of Xiamen University, supervised by professor "),r("a",{attrs:{href:"http://mingzeng.xyz/",target:"_blank",rel:"noopener noreferrer"}},[e._v("Ming Zeng"),r("OutboundLink")],1),e._v(".")]),e._v(" "),r("p",[e._v("I had a fantastic experience as a research intern at Visual Computing Group, "),r("a",{attrs:{href:"https://www.msra.cn/",target:"_blank",rel:"noopener noreferrer"}},[e._v("Microsoft Research Asia(MSRA)"),r("OutboundLink")],1),e._v(", working with "),r("a",{attrs:{href:"https://jianminbao.github.io/",target:"_blank",rel:"noopener noreferrer"}},[e._v("Dr. Jianmin Bao"),r("OutboundLink")],1),e._v(", "),r("a",{attrs:{href:"https://www.microsoft.com/en-us/research/people/tinzhan/",target:"_blank",rel:"noopener noreferrer"}},[e._v("Dr. Ting Zhang"),r("OutboundLink")],1),e._v(", and "),r("a",{attrs:{href:"http://www.dongchen.pro/",target:"_blank",rel:"noopener noreferrer"}},[e._v("Dr. Dong Chen"),r("OutboundLink")],1),e._v(".")]),e._v(" "),r("p",[e._v("My research interests lie at human-centric computer vision. I serve as the reviewer of CVPR, ICCV, ECCV, AAAI.")]),e._v(" "),r("h2",{attrs:{id:"news"}},[e._v("News")]),e._v(" "),r("ul",[r("li",[e._v("[Feb. 2023] Our work MaskCLIP is accepted by CVPR 2023.")]),e._v(" "),r("li",[e._v("[Dec. 2022] Our work on singing head generation has been accepted by CVM2023 and will be published on CVMJ.")]),e._v(" "),r("li",[e._v("[Nov. 2022] Our work on multi-exposure image fusion named EMEF has been accepted by AAAI2023.")]),e._v(" "),r("li",[e._v("[Oct. 2022] I and my roommate "),r("a",{attrs:{href:"https://wenjindeng.netlify.app/",target:"_blank",rel:"noopener noreferrer"}},[e._v("Wenjin Deng"),r("OutboundLink")],1),e._v(" won the National Scholarship for Postgraduate Students at the same time.")]),e._v(" "),r("li",[e._v("[Sep. 2022] My tutorial about "),r("a",{attrs:{href:"https://arxiv.org/abs/2006.11239",target:"_blank",rel:"noopener noreferrer"}},[e._v("Denoising Diffusion Probabilistic Models"),r("OutboundLink")],1),e._v(" is available on "),r("a",{attrs:{href:"https://www.bilibili.com/video/BV1rW4y1Y7M5/",target:"_blank",rel:"noopener noreferrer"}},[e._v("Bilibili"),r("OutboundLink")],1),e._v(".")]),e._v(" "),r("li",[e._v("[Jun. 2022] The "),r("a",{attrs:{href:"https://github.com/FacePerceiver/LAION-Face",target:"_blank",rel:"noopener noreferrer"}},[e._v("LAION-Face"),r("OutboundLink")],1),e._v(" dataset was released to support large-scale face pretraining.")]),e._v(" "),r("li",[e._v("[Jun. 2022] I received the reward of Excellent from the Star of Tomorrow Internship program in Microsoft Research Asia.")]),e._v(" "),r("li",[e._v("[Apr. 2022] Our work on multi-person pose estimation named "),r("strong",[e._v("I^2R-Net")]),e._v(" is accepted by IJCAI 2022.")]),e._v(" "),r("li",[e._v("[Mar. 2022] "),r("a",{attrs:{href:"https://github.com/FacePerceiver/FaRL",target:"_blank",rel:"noopener noreferrer"}},[e._v("FaRL"),r("OutboundLink")],1),e._v(" is accepted by CVPR 2022 as oral presentation.")]),e._v(" "),r("li",[e._v("[Dec. 2021] Our work on general facial representation learning named "),r("strong",[e._v("FaRL")]),e._v(" is released, code available on "),r("a",{attrs:{href:"https://github.com/FacePerceiver/FaRL",target:"_blank",rel:"noopener noreferrer"}},[e._v("Github"),r("OutboundLink")],1),e._v(".")]),e._v(" "),r("li",[e._v("[Jul. 2021] Our work on Deepfake Detection accepted by ICCV 2021.")])]),e._v(" "),r("h2",{attrs:{id:"publications"}},[e._v("Publications")]),e._v(" "),r("ProjectCard",{attrs:{hideBorder:"true",image:"https://s1.ax1x.com/2022/08/29/vfir5D.png"}},[r("p",[e._v("MaskCLIP: Masked Self-Distillation Advances Contrastive Language-Image Pretraining")]),e._v(" "),r("p",[e._v("Xiaoyi Dong, Jianmin Bao, "),r("strong",[e._v("Yinglin Zheng")]),e._v(", Ting Zhang, Dongdong Chen, Hao Yang, Ming Zeng, Weiming Zhang, Lu Yuan, Dong Chen, Fang Wen, Nenghai Yu")]),e._v(" "),r("p",[e._v("2023, IEEE Conference on Computer Vision and Pattern Recognition(CVPR)")]),e._v(" "),r("p",[r("a",{attrs:{href:"https://arxiv.org/abs/2208.12262",target:"_blank",rel:"noopener noreferrer"}},[e._v("Paper"),r("OutboundLink")],1)])]),e._v(" "),r("ProjectCard",{attrs:{hideBorder:"true",image:"/projects/musicface.png"}},[r("p",[e._v("MusicFace: Music-driven Expressive Singing Face Synthesis")]),e._v(" "),r("p",[e._v("Pengfei Liu, Wenjin Deng, Hengda Li, Jintai Wang, "),r("strong",[e._v("Yinglin Zheng")]),e._v(", Yiwei Ding, Xiaohu Guo, Ming Zeng*")]),e._v(" "),r("p",[e._v("2023, Computational Visual Media(CVMJ 2023)")]),e._v(" "),r("p",[r("a",{attrs:{href:"https://vcg.xmu.edu.cn/datasets/singingface/index.html",target:"_blank",rel:"noopener noreferrer"}},[e._v("Dataset"),r("OutboundLink")],1)])]),e._v(" "),r("ProjectCard",{attrs:{hideBorder:"true",image:"/projects/emef.png"}},[r("p",[e._v("EMEF: Ensemble Multi-Exposure Image Fusion")]),e._v(" "),r("p",[e._v("Renshuai Liu, Chengyang Li, Haitao Cao, "),r("strong",[e._v("Yinglin Zheng")]),e._v(", Ming Zeng, Xuan Cheng*")]),e._v(" "),r("p",[e._v("2023, AAAI Conference on Artificial Intelligence (AAAI), Oral presentation.")]),e._v(" "),r("p",[r("a",{attrs:{href:"https://github.com/medalwill/EMEF",target:"_blank",rel:"noopener noreferrer"}},[e._v("Project"),r("OutboundLink")],1)])]),e._v(" "),r("ProjectCard",{attrs:{hideBorder:"true",image:"https://s1.ax1x.com/2022/04/21/LyGJKK.png"}},[r("p",[e._v("I^2R-Net: Intra- and Inter-Human Relation Network for Multi-Person Pose Estimation")]),e._v(" "),r("p",[e._v("Yiwei Ding, Wenjin Deng, "),r("strong",[e._v("Yinglin Zheng")]),e._v(", Pengfei Liu, Jianmin Bao, Meihong Wang, Xuan Cheng, Ming Zeng, Dong Chen")]),e._v(" "),r("p",[e._v("2022, The 31st International Joint Conference on Artificial Intelligence (IJCAI-22)")]),e._v(" "),r("p",[r("a",{attrs:{href:"https://arxiv.org/abs/2206.10892",target:"_blank",rel:"noopener noreferrer"}},[e._v("Paper"),r("OutboundLink")],1),e._v(" "),r("a",{attrs:{href:"https://github.com/leijue222/Intra-and-Inter-Human-Relation-Network-for-MPEE",target:"_blank",rel:"noopener noreferrer"}},[e._v("Code"),r("OutboundLink")],1)])]),e._v(" "),r("ProjectCard",{attrs:{hideBorder:"true",image:"https://s4.ax1x.com/2021/12/08/oRXqhj.png"}},[r("p",[e._v("General Facial Representation Learning in a Visual-Linguistic Manner")]),e._v(" "),r("p",[r("strong",[e._v("Yinglin Zheng")]),e._v(", Hao Yang, Ting Zhang, Jianmin Bao, Dongdong Chen, Yangyu Huang, Lu Yuan, Dong Chen, Ming Zeng, Fang Wen")]),e._v(" "),r("p",[e._v("2022, IEEE Conference on Computer Vision and Pattern Recognition(CVPR), Oral presentation.")]),e._v(" "),r("p",[r("a",{attrs:{href:"https://arxiv.org/abs/2112.03109",target:"_blank",rel:"noopener noreferrer"}},[e._v("Paper"),r("OutboundLink")],1),e._v(" "),r("a",{attrs:{href:"https://github.com/FacePerceiver/FaRL",target:"_blank",rel:"noopener noreferrer"}},[e._v("Code"),r("OutboundLink")],1),e._v(" "),r("a",{attrs:{href:"https://github.com/FacePerceiver/LAION-Face",target:"_blank",rel:"noopener noreferrer"}},[e._v("Dataset"),r("OutboundLink")],1)])]),e._v(" "),r("ProjectCard",{attrs:{hideBorder:"true",image:"/projects/ftcn.png"}},[r("p",[e._v("Exploring Temporal Coherence for More General Video Face Forgery Detection")]),e._v(" "),r("p",[r("strong",[e._v("Yinglin Zheng")]),e._v(", Jianmin Bao, Dong Chen, Ming Zeng, Fang Wen")]),e._v(" "),r("p",[e._v("2021, International Conference on Computer Vision(ICCV)")]),e._v(" "),r("p",[r("a",{attrs:{href:"https://arxiv.org/abs/2108.06693",target:"_blank",rel:"noopener noreferrer"}},[e._v("Paper"),r("OutboundLink")],1),e._v(" "),r("a",{attrs:{href:"https://github.com/yinglinzheng/FTCN",target:"_blank",rel:"noopener noreferrer"}},[e._v("Code"),r("OutboundLink")],1)])]),e._v(" "),r("ProjectCard",{attrs:{hideBorder:"true",image:"/projects/mask_face.png"}},[r("p",[e._v("Real-time Masked Face Revealing for Video Conference")]),e._v(" "),r("p",[e._v("Jinpeng Lin, Pengfei Liu, "),r("strong",[e._v("Yinglin Zheng")]),e._v(", Wenjin Deng, Ming Zeng")]),e._v(" "),r("p",[e._v("2021, IEEE International Conference on Multimedia and Expo (ICME), Oral presentation.")])]),e._v(" "),r("ProjectCard",{attrs:{hideBorder:"true",image:"/projects/uv_iccv.png"}},[r("p",[e._v("UV空间中的人脸颜色纹理和几何细节协同补全")]),e._v(" "),r("p",[e._v("程轩，刘仁帅，"),r("strong",[e._v("郑英林")]),e._v("，曾鸣")]),e._v(" "),r("p",[e._v("2020, Chinagraph")])]),e._v(" "),r("ProjectCard",{attrs:{hideBorder:"true",image:"/projects/vh3d.png"}},[r("p",[e._v("VH3D-LSFM:Video-based Human 3D Pose Estimation with Long-term and Short-term Pose Fusion Mechanism")]),e._v(" "),r("p",[e._v("Wenjin Deng, "),r("strong",[e._v("Yinglin Zheng")]),e._v(", Hui Li, Xianwei Wang, Zizhao Wu, Ming Zeng")]),e._v(" "),r("p",[e._v("2020, Chinese Conference on Pattern Recognition and Computer Vision(PRCV)")]),e._v(" "),r("p",[r("a",{attrs:{href:"https://www.researchgate.net/publication/346167722_VH3D-LSFM_Video-Based_Human_3D_Pose_Estimation_with_Long-Term_and_Short-Term_Pose_Fusion_Mechanism",target:"_blank",rel:"noopener noreferrer"}},[e._v("Link"),r("OutboundLink")],1)])]),e._v(" "),r("ProjectCard",{attrs:{hideBorder:"true",image:"/projects/denoise.png"}},[r("p",[e._v("Spatially Adaptive Regularizer for Mesh Denoising")]),e._v(" "),r("p",[e._v("Xuan Cheng, "),r("strong",[e._v("Yinglin Zheng")]),e._v(", Yuhui Zheng, Fang Chen, Kunhui Lin")]),e._v(" "),r("p",[e._v("2020, IEEE Access")]),e._v(" "),r("p",[r("a",{attrs:{href:"https://www.researchgate.net/publication/340572393_Spatially_Adaptive_Regularizer_for_Mesh_Denoising",target:"_blank",rel:"noopener noreferrer"}},[e._v("Link"),r("OutboundLink")],1)])]),e._v(" "),r("ProjectCard",{attrs:{hideBorder:"true",image:"/projects/joint.png"}},[r("p",[e._v("Joint Depth-Face Translation and Facial Alignment via Multi-task Learning")]),e._v(" "),r("p",[e._v("2019, Multimedia Tools and Applications")]),e._v(" "),r("p",[e._v("Xiaoli Wang, "),r("strong",[e._v("Yinglin Zheng")]),e._v(", Ming Zeng, Xuan Cheng, Wei Lu.")]),e._v(" "),r("p",[r("a",{attrs:{href:"https://www.researchgate.net/publication/341411157_Joint_learning_for_face_alignment_and_face_transfer_with_depth_image",target:"_blank",rel:"noopener noreferrer"}},[e._v("Link"),r("OutboundLink")],1)])]),e._v(" "),r("h2",{attrs:{id:"awards-honors"}},[e._v("Awards & Honors")]),e._v(" "),r("ul",[r("li",[e._v("National Scholarship for Graduate Students, 2022")]),e._v(" "),r("li",[e._v("Stars of Tomorrow (Award of Excellent Intern), Microsoft Research Asia, 2022")]),e._v(" "),r("li",[r("strong",[e._v("Rank 10")]),e._v(" among 2265 teams in "),r("strong",[e._v("Kaggle Deepfake Detection Challenge")]),e._v(".")]),e._v(" "),r("li",[r("strong",[e._v("Champion")]),e._v(" of 3D Face Alignment in the Wild Challenge (In conjunction with ICCV 2019), Seoul, Korea, 2019.")])]),e._v(" "),r("h2",{attrs:{id:"education-experiences"}},[e._v("Education & Experiences")]),e._v(" "),r("ul",[r("li",[r("p",[r("strong",[e._v("Research Intern, Visual Computing Group, Microsoft Research Asia")]),e._v(" "),r("br"),e._v("\nDec. 2022 - Mar. 2024")])]),e._v(" "),r("li",[r("p",[r("strong",[e._v("Research Intern, Visual Computing Group, Microsoft Research Asia")]),e._v(" "),r("br"),e._v("\nSep. 2020 - Mar. 2022")])]),e._v(" "),r("li",[r("p",[r("strong",[e._v("Doctoral Student of Computer Science, School of Informatics, Xiamen University")]),e._v(" "),r("br"),e._v("\nSep. 2020 - present")])]),e._v(" "),r("li",[r("p",[r("strong",[e._v("Bachelor of Software Engineering, School of Informatics, Xiamen University")]),e._v(" "),r("br"),e._v("\nSep. 2016 - Jun. 2020")])])])],1)}),[],!1,null,null,null);n.default=a.exports}}]);